{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1252,
          "sourceType": "datasetVersion",
          "datasetId": 655
        },
        {
          "sourceId": 3919,
          "sourceType": "datasetVersion",
          "datasetId": 2321
        },
        {
          "sourceId": 4877,
          "sourceType": "datasetVersion",
          "datasetId": 2894
        },
        {
          "sourceId": 5624,
          "sourceType": "datasetVersion",
          "datasetId": 3491
        },
        {
          "sourceId": 8172,
          "sourceType": "datasetVersion",
          "datasetId": 1442
        },
        {
          "sourceId": 13206,
          "sourceType": "datasetVersion",
          "datasetId": 9366
        },
        {
          "sourceId": 403916,
          "sourceType": "datasetVersion",
          "datasetId": 179555
        },
        {
          "sourceId": 466349,
          "sourceType": "datasetVersion",
          "datasetId": 4549
        },
        {
          "sourceId": 1151655,
          "sourceType": "datasetVersion",
          "datasetId": 2478
        },
        {
          "sourceId": 5438389,
          "sourceType": "datasetVersion",
          "datasetId": 10128
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Exercise: Summary Functions and Maps",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "nolanbconaway_pitchfork_data_path = kagglehub.dataset_download('nolanbconaway/pitchfork-data')\n",
        "datasnaek_chess_path = kagglehub.dataset_download('datasnaek/chess')\n",
        "organizations_nasa_kepler_exoplanet_search_results_path = kagglehub.dataset_download('organizations/nasa/kepler-exoplanet-search-results')\n",
        "residentmario_things_on_reddit_path = kagglehub.dataset_download('residentmario/things-on-reddit')\n",
        "zynicide_wine_reviews_path = kagglehub.dataset_download('zynicide/wine-reviews')\n",
        "residentmario_ramen_ratings_path = kagglehub.dataset_download('residentmario/ramen-ratings')\n",
        "dansbecker_powerlifting_database_path = kagglehub.dataset_download('dansbecker/powerlifting-database')\n",
        "datasnaek_youtube_new_path = kagglehub.dataset_download('datasnaek/youtube-new')\n",
        "rtatman_188_million_us_wildfires_path = kagglehub.dataset_download('rtatman/188-million-us-wildfires')\n",
        "jpmiller_publicassistance_path = kagglehub.dataset_download('jpmiller/publicassistance')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "dlzzV-JNNG_y"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook is an exercise in the [Pandas](https://www.kaggle.com/learn/pandas) course.  You can reference the tutorial at [this link](https://www.kaggle.com/residentmario/summary-functions-and-maps).**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "FWOI5WRFNG_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Now you are ready to get a deeper understanding of your data.\n",
        "\n",
        "Run the following cell to load your data and some utility functions (including code to check your answers)."
      ],
      "metadata": {
        "id": "bctOAG2yNG_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", 5)\n",
        "reviews = pd.read_csv(\"../input/wine-reviews/winemag-data-130k-v2.csv\", index_col=0)\n",
        "\n",
        "from learntools.core import binder; binder.bind(globals())\n",
        "from learntools.pandas.summary_functions_and_maps import *\n",
        "print(\"Setup complete.\")\n",
        "\n",
        "reviews.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:30:18.271417Z",
          "iopub.execute_input": "2025-03-25T11:30:18.271746Z",
          "iopub.status.idle": "2025-03-25T11:30:25.81832Z",
          "shell.execute_reply.started": "2025-03-25T11:30:18.27172Z",
          "shell.execute_reply": "2025-03-25T11:30:25.817234Z"
        },
        "id": "KPdVswyGNG_1",
        "outputId": "5390ee0c-2dee-4e42-a9cf-abed6c842a68"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Setup complete.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.10/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
          "output_type": "stream"
        },
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "    country                                        description  \\\n0     Italy  Aromas include tropical fruit, broom, brimston...   \n1  Portugal  This is ripe and fruity, a wine that is smooth...   \n2        US  Tart and snappy, the flavors of lime flesh and...   \n3        US  Pineapple rind, lemon pith and orange blossom ...   \n4        US  Much like the regular bottling from 2012, this...   \n\n                          designation  points  price           province  \\\n0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n1                            Avidagos      87   15.0              Douro   \n2                                 NaN      87   14.0             Oregon   \n3                Reserve Late Harvest      87   13.0           Michigan   \n4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n\n              region_1           region_2         taster_name  \\\n0                 Etna                NaN       Kerin O’Keefe   \n1                  NaN                NaN          Roger Voss   \n2    Willamette Valley  Willamette Valley        Paul Gregutt   \n3  Lake Michigan Shore                NaN  Alexander Peartree   \n4    Willamette Valley  Willamette Valley        Paul Gregutt   \n\n  taster_twitter_handle                                              title  \\\n0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n\n          variety               winery  \n0     White Blend              Nicosia  \n1  Portuguese Red  Quinta dos Avidagos  \n2      Pinot Gris            Rainstorm  \n3        Riesling           St. Julian  \n4      Pinot Noir         Sweet Cheeks  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>country</th>\n      <th>description</th>\n      <th>designation</th>\n      <th>points</th>\n      <th>price</th>\n      <th>province</th>\n      <th>region_1</th>\n      <th>region_2</th>\n      <th>taster_name</th>\n      <th>taster_twitter_handle</th>\n      <th>title</th>\n      <th>variety</th>\n      <th>winery</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Italy</td>\n      <td>Aromas include tropical fruit, broom, brimston...</td>\n      <td>Vulkà Bianco</td>\n      <td>87</td>\n      <td>NaN</td>\n      <td>Sicily &amp; Sardinia</td>\n      <td>Etna</td>\n      <td>NaN</td>\n      <td>Kerin O’Keefe</td>\n      <td>@kerinokeefe</td>\n      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n      <td>White Blend</td>\n      <td>Nicosia</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Portugal</td>\n      <td>This is ripe and fruity, a wine that is smooth...</td>\n      <td>Avidagos</td>\n      <td>87</td>\n      <td>15.0</td>\n      <td>Douro</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Roger Voss</td>\n      <td>@vossroger</td>\n      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n      <td>Portuguese Red</td>\n      <td>Quinta dos Avidagos</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>US</td>\n      <td>Tart and snappy, the flavors of lime flesh and...</td>\n      <td>NaN</td>\n      <td>87</td>\n      <td>14.0</td>\n      <td>Oregon</td>\n      <td>Willamette Valley</td>\n      <td>Willamette Valley</td>\n      <td>Paul Gregutt</td>\n      <td>@paulgwine</td>\n      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n      <td>Pinot Gris</td>\n      <td>Rainstorm</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>US</td>\n      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n      <td>Reserve Late Harvest</td>\n      <td>87</td>\n      <td>13.0</td>\n      <td>Michigan</td>\n      <td>Lake Michigan Shore</td>\n      <td>NaN</td>\n      <td>Alexander Peartree</td>\n      <td>NaN</td>\n      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n      <td>Riesling</td>\n      <td>St. Julian</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>US</td>\n      <td>Much like the regular bottling from 2012, this...</td>\n      <td>Vintner's Reserve Wild Child Block</td>\n      <td>87</td>\n      <td>65.0</td>\n      <td>Oregon</td>\n      <td>Willamette Valley</td>\n      <td>Willamette Valley</td>\n      <td>Paul Gregutt</td>\n      <td>@paulgwine</td>\n      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n      <td>Pinot Noir</td>\n      <td>Sweet Cheeks</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercises"
      ],
      "metadata": {
        "id": "xebinmNANG_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.\n",
        "\n",
        "What is the median of the `points` column in the `reviews` DataFrame?"
      ],
      "metadata": {
        "id": "Lvwua2YyNG_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "median_points = reviews.points.median()\n",
        "\n",
        "# Check your answer\n",
        "q1.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:30:36.260194Z",
          "iopub.execute_input": "2025-03-25T11:30:36.260625Z",
          "iopub.status.idle": "2025-03-25T11:30:36.270844Z",
          "shell.execute_reply.started": "2025-03-25T11:30:36.260587Z",
          "shell.execute_reply": "2025-03-25T11:30:36.269777Z"
        },
        "id": "QwkhqwRgNG_2",
        "outputId": "f76be3f0-bb46-4540-f98d-e149bb896096"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.14285714285714285, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"1_MedianPoints\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#q1.hint()\n",
        "#q1.solution()"
      ],
      "metadata": {
        "id": "BpxPtaJyNG_3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.\n",
        "What countries are represented in the dataset? (Your answer should not include any duplicates.)"
      ],
      "metadata": {
        "id": "vVGsYDWqNG_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "countries = reviews.country.unique()\n",
        "\n",
        "# Check your answer\n",
        "q2.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:31:30.661912Z",
          "iopub.execute_input": "2025-03-25T11:31:30.662311Z",
          "iopub.status.idle": "2025-03-25T11:31:30.674293Z",
          "shell.execute_reply.started": "2025-03-25T11:31:30.662281Z",
          "shell.execute_reply": "2025-03-25T11:31:30.673408Z"
        },
        "id": "rthX9-NgNG_3",
        "outputId": "1e93e6f6-a477-44fd-c705-48478deb7253"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.14285714285714285, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"2_UniqueCountries\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#q2.hint()\n",
        "#q2.solution()"
      ],
      "metadata": {
        "id": "e0-ni4ovNG_4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.\n",
        "How often does each country appear in the dataset? Create a Series `reviews_per_country` mapping countries to the count of reviews of wines from that country."
      ],
      "metadata": {
        "id": "qUBJQ2FBNG_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_per_country = reviews.country.value_counts()\n",
        "\n",
        "# Check your answer\n",
        "q3.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:37:20.785379Z",
          "iopub.execute_input": "2025-03-25T11:37:20.785704Z",
          "iopub.status.idle": "2025-03-25T11:37:20.805626Z",
          "shell.execute_reply.started": "2025-03-25T11:37:20.785681Z",
          "shell.execute_reply": "2025-03-25T11:37:20.804323Z"
        },
        "id": "5GX5_efPNG_4",
        "outputId": "0c45634c-048a-456f-e915-e52b288ca8ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.14285714285714285, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"3_ReviewsPerCountry\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#q3.hint()\n",
        "#q3.solution()"
      ],
      "metadata": {
        "id": "ebNiIhdANG_4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.\n",
        "Create variable `centered_price` containing a version of the `price` column with the mean price subtracted.\n",
        "\n",
        "(Note: this 'centering' transformation is a common preprocessing step before applying various machine learning algorithms.)"
      ],
      "metadata": {
        "id": "ewq65A_hNG_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "centered_price = reviews.price - reviews.price.mean()\n",
        "\n",
        "# Check your answer\n",
        "q4.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:43:03.511385Z",
          "iopub.execute_input": "2025-03-25T11:43:03.511708Z",
          "iopub.status.idle": "2025-03-25T11:43:03.522823Z",
          "shell.execute_reply.started": "2025-03-25T11:43:03.511684Z",
          "shell.execute_reply": "2025-03-25T11:43:03.521759Z"
        },
        "id": "a3-rRGDhNG_4",
        "outputId": "eb603c2a-bb81-4201-b3bb-7e62934b5df4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.14285714285714285, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"4_CenteredPrice\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#q4.hint()\n",
        "#q4.solution()"
      ],
      "metadata": {
        "id": "IjanqyhRNG_4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.\n",
        "I'm an economical wine buyer. Which wine is the \"best bargain\"? Create a variable `bargain_wine` with the title of the wine with the highest points-to-price ratio in the dataset."
      ],
      "metadata": {
        "id": "R3Pd8_-DNG_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the points-to-price ratio\n",
        "ratio = reviews.points / reviews.price\n",
        "\n",
        "# Find the index of the wine with the highest ratio\n",
        "best_bargain_index = ratio.idxmax()\n",
        "\n",
        "# Get the title of the wine at that index\n",
        "bargain_wine = reviews.loc[best_bargain_index, 'title']\n",
        "\n",
        "# Check your answer\n",
        "q5.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:48:05.705229Z",
          "iopub.execute_input": "2025-03-25T11:48:05.705548Z",
          "iopub.status.idle": "2025-03-25T11:48:05.728981Z",
          "shell.execute_reply.started": "2025-03-25T11:48:05.70552Z",
          "shell.execute_reply": "2025-03-25T11:48:05.72776Z"
        },
        "id": "wYBJ98WuNG_5",
        "outputId": "3c8f3271-c10d-4786-feda-b7533e5af154"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.14285714285714285, \"interactionType\": 1, \"questionType\": 2, \"questionId\": \"5_BargainWine\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#q5.hint()\n",
        "#q5.solution()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:45:55.98839Z",
          "iopub.execute_input": "2025-03-25T11:45:55.988752Z",
          "iopub.status.idle": "2025-03-25T11:45:55.99704Z",
          "shell.execute_reply.started": "2025-03-25T11:45:55.98871Z",
          "shell.execute_reply": "2025-03-25T11:45:55.995992Z"
        },
        "id": "6w3C3xVaNG_5",
        "outputId": "ac2357ea-8ab3-442e-9d1e-259eeff9923a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 2, \"questionId\": \"5_BargainWine\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Hint: The `idxmax` method may be useful here.",
            "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> The `idxmax` method may be useful here."
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.\n",
        "There are only so many words you can use when describing a bottle of wine. Is a wine more likely to be \"tropical\" or \"fruity\"? Create a Series `descriptor_counts` counting how many times each of these two words appears in the `description` column in the dataset. (For simplicity, let's ignore the capitalized versions of these words.)"
      ],
      "metadata": {
        "id": "45dAw6dZNG_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_trop = reviews.description.map(lambda desc: \"tropical\" in desc).sum()\n",
        "n_fruity = reviews.description.map(lambda desc: \"fruity\" in desc).sum()\n",
        "descriptor_counts = pd.Series([n_trop, n_fruity], index=['tropical', 'fruity'])\n",
        "\n",
        "# Check the answer\n",
        "q6.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:58:52.648367Z",
          "iopub.execute_input": "2025-03-25T11:58:52.648714Z",
          "iopub.status.idle": "2025-03-25T11:58:52.789247Z",
          "shell.execute_reply.started": "2025-03-25T11:58:52.648685Z",
          "shell.execute_reply": "2025-03-25T11:58:52.788315Z"
        },
        "id": "7ESTQ9hYNG_5",
        "outputId": "67808ba8-2ec9-4213-cfc0-3844dcd393f7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 0.14285714285714285, \"interactionType\": 1, \"questionType\": 1, \"questionId\": \"6_DescriptorCounts\", \"learnToolsVersion\": \"0.3.4\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Correct",
            "text/markdown": "<span style=\"color:#33cc33\">Correct</span>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#q6.hint()\n",
        "#q6.solution()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T11:58:57.221668Z",
          "iopub.execute_input": "2025-03-25T11:58:57.222107Z",
          "iopub.status.idle": "2025-03-25T11:58:57.226178Z",
          "shell.execute_reply.started": "2025-03-25T11:58:57.222075Z",
          "shell.execute_reply": "2025-03-25T11:58:57.224996Z"
        },
        "id": "eTSEzBQsNG_5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.\n",
        "We'd like to host these wine reviews on our website, but a rating system ranging from 80 to 100 points is too hard to understand - we'd like to translate them into simple star ratings. A score of 95 or higher counts as 3 stars, a score of at least 85 but less than 95 is 2 stars. Any other score is 1 star.\n",
        "\n",
        "Also, the Canadian Vintners Association bought a lot of ads on the site, so any wines from Canada should automatically get 3 stars, regardless of points.\n",
        "\n",
        "Create a series `star_ratings` with the number of stars corresponding to each review in the dataset."
      ],
      "metadata": {
        "id": "qdh4I322NG_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def re_rating(row):\n",
        "    if row.country == 'Canada':\n",
        "        return 3\n",
        "    if row.points >= 95:\n",
        "        return 3\n",
        "    elif row.points >= 85:\n",
        "        return 2\n",
        "    else:\n",
        "        return 1\n",
        "star_ratings = reviews.apply(re_rating, axis=1)\n",
        "# Check your answer\n",
        "q7.check()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T12:07:21.424806Z",
          "iopub.execute_input": "2025-03-25T12:07:21.425234Z",
          "iopub.status.idle": "2025-03-25T12:07:21.438554Z",
          "shell.execute_reply.started": "2025-03-25T12:07:21.425201Z",
          "shell.execute_reply": "2025-03-25T12:07:21.436774Z"
        },
        "id": "IZ9fxIsDNG_5",
        "outputId": "460dd7f6-153a-460a-b589-9d65dced42c3"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1a0833a2dfc0>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mstar_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre_rating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Check your answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'series'"
          ],
          "ename": "AttributeError",
          "evalue": "module 'pandas' has no attribute 'series'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "q7.hint()\n",
        "#q7.solution()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-25T12:00:21.690368Z",
          "iopub.execute_input": "2025-03-25T12:00:21.690721Z",
          "iopub.status.idle": "2025-03-25T12:00:21.697756Z",
          "shell.execute_reply.started": "2025-03-25T12:00:21.69069Z",
          "shell.execute_reply": "2025-03-25T12:00:21.696955Z"
        },
        "id": "JMXAcmDDNG_6",
        "outputId": "11523a56-904f-4173-d30d-8064d46d39f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.Javascript object>",
            "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"interactionType\": 2, \"questionType\": 1, \"questionId\": \"7_StarRatings\", \"learnToolsVersion\": \"0.3.4\", \"valueTowardsCompletion\": 0.0, \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\", \"outcomeType\": 4}}, \"*\")"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Hint: Begin by writing a custom function that accepts a row from the DataFrame as input and returns the star rating corresponding to the row.  Then, use `DataFrame.apply` to apply the custom function to every row in the dataset.",
            "text/markdown": "<span style=\"color:#3366cc\">Hint:</span> Begin by writing a custom function that accepts a row from the DataFrame as input and returns the star rating corresponding to the row.  Then, use `DataFrame.apply` to apply the custom function to every row in the dataset."
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keep going\n",
        "Continue to **[grouping and sorting](https://www.kaggle.com/residentmario/grouping-and-sorting)**."
      ],
      "metadata": {
        "id": "jbPk7CZ5NG_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/pandas/discussion) to chat with other learners.*"
      ],
      "metadata": {
        "id": "z-Pt6feoNG_6"
      }
    }
  ]
}